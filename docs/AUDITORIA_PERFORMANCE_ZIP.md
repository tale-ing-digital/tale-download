# ğŸ“Š REPORTE DE AUDITORÃA DE PERFORMANCE
## TaleDownload - Pipeline de GeneraciÃ³n de ZIP

**Fecha:** 21 de Diciembre, 2025  
**VersiÃ³n:** 1.0.0  
**Estado:** Solo anÃ¡lisis (sin modificaciones)

---

## 1ï¸âƒ£ RESUMEN EJECUTIVO (No TÃ©cnico)

La aplicaciÃ³n TaleDownload tiene un problema de rendimiento en la generaciÃ³n de ZIPs que se debe principalmente a un **diseÃ±o secuencial** donde cada archivo se descarga, convierte y procesa uno tras otro. Si un proyecto tiene 500 documentos, el sistema espera a que cada uno termine completamente antes de empezar con el siguiente.

**Tiempo estimado actual:**
- Cada documento: ~2-5 segundos (descarga + conversiÃ³n)
- Proyecto de 500 docs: **~15-40 minutos** (solo en procesamiento)

**Factores agravantes identificados:**
- Todo el ZIP se mantiene en memoria RAM hasta terminar
- No hay lÃ­mites de recursos en el contenedor Docker
- El cliente espera sin feedback real de progreso

---

## 2ï¸âƒ£ FLUJO TÃ‰CNICO DETALLADO

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FLUJO COMPLETO DE GENERACIÃ“N ZIP                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[FRONTEND - React]
   â”‚
   â”œâ”€ 1. Usuario hace clic en "Descargar ZIP"
   â”‚     â””â”€ handleDownloadProjectZip() â†’ Home.tsx#L97
   â”‚
   â”œâ”€ 2. Axios GET /api/download/zip/project/{code}
   â”‚     â””â”€ timeout: 0 (infinito) â†’ api.ts#L247
   â”‚     â””â”€ responseType: 'blob' (espera TODO el contenido)
   â”‚
   â–¼
[BACKEND - FastAPI]
   â”‚
   â”œâ”€ 3. async def download_project_zip() â†’ routes.py#L261
   â”‚     â””â”€ âš ï¸ ASYNC pero llama servicios SYNC bloqueantes
   â”‚
   â”œâ”€ 4. redshift_service.get_documents() â†’ redshift_service.py#L94
   â”‚     â”œâ”€ ConexiÃ³n via psycopg2 (sync, bloqueante)
   â”‚     â”œâ”€ Query CTE compleja con CASE de clasificaciÃ³n
   â”‚     â”œâ”€ LIMIT: 100,000 documentos mÃ¡ximo
   â”‚     â””â”€ Retorna lista completa en memoria
   â”‚
   â”œâ”€ 5. zip_service.create_zip() â†’ zip_service.py#L156
   â”‚     â”œâ”€ BytesIO zip_buffer (TODO en RAM)
   â”‚     â”‚
   â”‚     â”œâ”€ FOR EACH documento (SECUENCIAL):
   â”‚     â”‚   â”‚
   â”‚     â”‚   â”œâ”€ 5a. download_service.download_file(url)
   â”‚     â”‚   â”‚       â”œâ”€ requests.get() con stream=True
   â”‚     â”‚   â”‚       â”œâ”€ âš ï¸ PERO usa response.content (carga todo en RAM)
   â”‚     â”‚   â”‚       â””â”€ timeout: 30s por archivo
   â”‚     â”‚   â”‚
   â”‚     â”‚   â”œâ”€ 5b. pdf_service.convert_to_pdf(content)
   â”‚     â”‚   â”‚       â”œâ”€ Si ya es PDF â†’ passthrough
   â”‚     â”‚   â”‚       â””â”€ Si es imagen â†’ PIL + ReportLab â†’ PDF
   â”‚     â”‚   â”‚           â”œâ”€ Image.open() en memoria
   â”‚     â”‚   â”‚           â”œâ”€ canvas.Canvas() en BytesIO
   â”‚     â”‚   â”‚           â””â”€ âš ï¸ Doble copia en RAM
   â”‚     â”‚   â”‚
   â”‚     â”‚   â””â”€ 5c. zip_file.writestr(path, pdf_content)
   â”‚     â”‚           â””â”€ Acumula en zip_buffer (RAM)
   â”‚     â”‚
   â”‚     â””â”€ zip_buffer.seek(0) â†’ retorna BytesIO completo
   â”‚
   â”œâ”€ 6. StreamingResponse(zip_buffer)
   â”‚     â””â”€ âš ï¸ NO es streaming real: buffer ya estÃ¡ completo
   â”‚
   â–¼
[FRONTEND - React]
   â”‚
   â””â”€ 7. Recibe blob, crea URL, descarga archivo
```

---

## 3ï¸âƒ£ TABLA DE TIEMPOS POR ETAPA (ESTIMADO)

| Etapa | OperaciÃ³n | Tiempo Unitario | Para 500 docs |
|-------|-----------|-----------------|---------------|
| T0â†’T1 | Query Redshift | 1-5s | 1-5s |
| T1â†’T2 | Descargar archivo (c/u) | 0.5-3s | 250-1500s |
| T2â†’T3 | ConversiÃ³n PDF (c/u) | 0.1-1s (imÃ¡genes) | 50-500s |
| T3â†’T4 | Escritura en ZIP (c/u) | <0.01s | ~5s |
| T4â†’T5 | Transferencia a cliente | Variable | 10-60s |
| **TOTAL** | | | **5-35 min** |

**Nota:** No se pudo medir en vivo sin agregar instrumentaciÃ³n.

---

## 4ï¸âƒ£ CUELLOS DE BOTELLA REALES (Ordenados por Impacto)

### ğŸ”´ CRÃTICO #1: Descargas 100% Secuenciales

**UbicaciÃ³n:** `backend/services/zip_service.py#L174-L197`

```python
for idx, doc in enumerate(folder_docs, 1):  # â† SECUENCIAL
    content = download_service.download_file(url)  # â† BLOQUEANTE
```

**Impacto:** Si hay 500 docs y cada descarga toma 2s = **16 minutos solo en descargas**

**Evidencia:** Loop `for` sin concurrencia, `requests.get()` es sÃ­ncrono

---

### ğŸ”´ CRÃTICO #2: Todo en RAM (No Streaming Real)

**UbicaciÃ³n:** `backend/services/zip_service.py#L158`

```python
zip_buffer = io.BytesIO()  # â† TODO el ZIP se acumula aquÃ­
```

**Impacto:** 
- 500 docs Ã— ~500KB = ~250MB en RAM solo para el ZIP
- MÃ¡s las copias intermedias de imÃ¡genes/PDFs
- Picos de memoria de 1GB+ para proyectos grandes

**Evidencia:** `BytesIO()` sin flush a disco, `zip_buffer.seek(0)` al final

---

### ğŸ”´ CRÃTICO #3: Endpoint async pero Servicios sync

**UbicaciÃ³n:** `backend/api/routes.py#L261`

```python
async def download_project_zip(...):
    documents_data = redshift_service.get_documents(...)  # â† SYNC
    zip_buffer = zip_service.create_zip(...)  # â† SYNC
```

**Impacto:** Bloquea el event loop de Uvicorn mientras procesa

**Evidencia:** 
- `psycopg2` no es async
- `requests.get()` no es async
- `zipfile.ZipFile` no es async

---

### ğŸŸ  ALTO #4: stream=True pero response.content

**UbicaciÃ³n:** `backend/services/download_service.py#L25-L37`

```python
response = requests.get(url, timeout=timeout, stream=True)
# ...
content = response.content  # â† Lee TODO en memoria de golpe
```

**Impacto:** `stream=True` no sirve si usas `.content`

**Evidencia:** DeberÃ­a usar `iter_content()` para streaming real

---

### ğŸŸ  ALTO #5: Query CTE Compleja sin PaginaciÃ³n

**UbicaciÃ³n:** `backend/services/redshift_service.py#L139-L267`

**Impacto:** 
- Query de ~100 lÃ­neas ejecutada en cada request
- LIMIT 100,000 sin cursor/paginaciÃ³n
- Resultado completo en memoria antes de procesar

---

### ğŸŸ¡ MEDIO #6: ConversiÃ³n de Imagen CPU-bound

**UbicaciÃ³n:** `backend/services/pdf_service.py#L32-L66`

```python
image = Image.open(io.BytesIO(image_bytes))
image = image.convert('RGB')  # â† CPU-bound
c = canvas.Canvas(pdf_buffer)  # â† CPU-bound
```

**Impacto:** Para imÃ¡genes grandes, puede tomar 0.5-1s por archivo

**Evidencia:** PIL y ReportLab son CPU-bound, ejecutados en main thread

---

### ğŸŸ¡ MEDIO #7: Sin LÃ­mites de Recursos en Docker

**UbicaciÃ³n:** `deploy.ps1#L89-L94`

```powershell
docker run -d --name tale-download -p 8080:8080 --env-file .env
# â† Sin --memory, --cpus
```

**Impacto:** Puede consumir toda la RAM/CPU del host

**Evidencia:** No hay flags `--memory` ni `--cpus`

---

### ğŸŸ¢ BAJO #8: Uvicorn Single Worker por Defecto

**UbicaciÃ³n:** `backend/main.py#L68-L72`

```python
uvicorn.run("backend.main:app", host="0.0.0.0", port=8080, reload=settings.DEBUG)
# â† Sin workers=N, sin configuraciÃ³n de threads
```

**Impacto:** Solo 1 worker = 1 request de ZIP a la vez bloquea todo

**Evidencia:** Sin parÃ¡metro `workers`

---

## 5ï¸âƒ£ RIESGOS DETECTADOS

| Riesgo | Severidad | DescripciÃ³n |
|--------|-----------|-------------|
| **OOM Kill** | ğŸ”´ CRÃTICA | Proyectos grandes pueden agotar RAM del contenedor |
| **Timeout de Red** | ğŸŸ  ALTA | Requests HTTP de minutos pueden cerrarse por proxies intermedios |
| **Bloqueo de Otros Usuarios** | ğŸŸ  ALTA | Un ZIP grande bloquea el Ãºnico worker |
| **Sin Reintentos** | ğŸŸ¡ MEDIA | Si falla una descarga, no hay retry automÃ¡tico |
| **Sin Progress Real** | ğŸŸ¡ MEDIA | `onDownloadProgress` solo funciona cuando hay Content-Length conocido |

---

## 6ï¸âƒ£ RECOMENDACIONES TÃ‰CNICAS (SIN IMPLEMENTAR)

### QUICK WINS (Bajo esfuerzo, Alto impacto)

| # | RecomendaciÃ³n | Esfuerzo | Impacto |
|---|---------------|----------|---------|
| 1 | Agregar workers a Uvicorn: `workers=4` | ğŸŸ¢ Bajo | ğŸ”´ Alto |
| 2 | LÃ­mites de Docker: `--memory=2g --cpus=2` | ğŸŸ¢ Bajo | ğŸŸ  Medio |
| 3 | Timeout mÃ¡s corto por archivo: 15s en vez de 30s | ğŸŸ¢ Bajo | ğŸŸ¡ Bajo |
| 4 | Logging de tiempos: timestamps en cada etapa | ğŸŸ¢ Bajo | ğŸŸ¡ DiagnÃ³stico |

### CAMBIOS ESTRUCTURALES (Mayor esfuerzo)

| # | RecomendaciÃ³n | Esfuerzo | Impacto |
|---|---------------|----------|---------|
| 1 | Descargas Paralelas: `asyncio.gather()` con `aiohttp` | ğŸŸ  Medio | ğŸ”´ Alto |
| 2 | Streaming Real: ZIP a disco + streamear | ğŸŸ  Medio | ğŸ”´ Alto |
| 3 | Async DB: Cambiar `psycopg2` por `asyncpg` | ğŸŸ  Medio | ğŸŸ  Medio |
| 4 | Background Job: Generar ZIP en tarea async | ğŸ”´ Alto | ğŸ”´ Alto |
| 5 | Chunked Encoding: Enviar ZIP mientras se genera | ğŸ”´ Alto | ğŸ”´ Alto |

---

## 7ï¸âƒ£ COMPARATIVO: Â¿QuÃ© Pudo Cambiar?

| Factor | Antes | Ahora | Impacto |
|--------|-------|-------|---------|
| Cantidad de docs/proyecto | ~100 | ~500+ | â†‘ 5x tiempo |
| TamaÃ±o promedio de archivos | ~200KB | ~500KB+ | â†‘ 2.5x RAM |
| HomologaciÃ³n tipo_unidad | 4 tipos | 7 tipos | MÃ¡s carpetas en ZIP |
| Query de clasificaciÃ³n | Simple | CTE compleja | +1-2s por query |
| Cardinalidad | Baja | Alta | MÃ¡s filas procesadas |

---

## 8ï¸âƒ£ CHECKLIST PARA SIGUIENTE FASE

Cuando se decida proceder con fixes, priorizar:

- [ ] Instrumentar logging con timestamps (t0-t5)
- [ ] Medir proyecto real (cuÃ¡ntos docs, cuÃ¡nto tiempo)
- [ ] Agregar workers a Uvicorn (quick win)
- [ ] Agregar lÃ­mites de Docker (quick win)
- [ ] Evaluar si conviene descargas paralelas
- [ ] Evaluar si conviene background job + notificaciÃ³n

---

## 9ï¸âƒ£ ARCHIVOS ANALIZADOS

| Archivo | Rol en el Pipeline |
|---------|-------------------|
| `client/src/pages/Home.tsx` | Trigger del download |
| `client/src/lib/api.ts` | Axios config + blob handling |
| `backend/api/routes.py` | Endpoints FastAPI |
| `backend/services/zip_service.py` | Armado del ZIP |
| `backend/services/download_service.py` | Descarga de URLs |
| `backend/services/pdf_service.py` | ConversiÃ³n a PDF |
| `backend/services/redshift_service.py` | Queries a Redshift |
| `backend/main.py` | Config de Uvicorn |
| `backend/core/config.py` | Settings |
| `Containerfile` | Imagen Docker |
| `deploy.ps1` | Script de deploy |

---

## ğŸ”’ RESTRICCIONES APLICADAS

Durante esta auditorÃ­a:
- âœ… Solo lectura y anÃ¡lisis de cÃ³digo
- âœ… Sin modificaciones a lÃ³gica de negocio
- âœ… Sin cambios de arquitectura
- âœ… Sin optimizaciones aplicadas
- âœ… Sin cache agregado
- âœ… Sin paralelizaciÃ³n implementada

---

**FIN DEL REPORTE DE AUDITORÃA**

*Documento generado el 21 de Diciembre, 2025*
